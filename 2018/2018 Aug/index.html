
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.1, mkdocs-material-8.5.7">
    
    
      
        <title>2018 August Reading Reports - Haoyang's Paper Collections</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.20d9efc8.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cbb835fc.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#2018-august-reading-reports" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Haoyang&#39;s Paper Collections" class="md-header__button md-logo" aria-label="Haoyang's Paper Collections" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Haoyang's Paper Collections
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2018 August Reading Reports
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Haoyang&#39;s Paper Collections" class="md-nav__button md-logo" aria-label="Haoyang's Paper Collections" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Haoyang's Paper Collections
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../2021-2022/" class="md-nav__link">
        2021-2022
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          2020
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="2020" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          2020
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2020/2020%20Oct/" class="md-nav__link">
        2020 Oct
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2020/2020%20Sep/" class="md-nav__link">
        2020 Sep
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2020/2020%20Aug/" class="md-nav__link">
        2020 Aug
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2020/2020%20Jul/" class="md-nav__link">
        2020 Jul
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2020/2020%20Jun/" class="md-nav__link">
        2020 Jun
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2020/2020%20May/" class="md-nav__link">
        2020 May
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2020/2020%20Apr/" class="md-nav__link">
        2020 Apr
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          2019
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="2019" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          2019
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2019/2019%20Dec/" class="md-nav__link">
        2019 Dec
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#an-efficient-solution-to-the-five-point-relative-pose-problem" class="md-nav__link">
    An Efficient Solution to the Five-Point Relative Pose Problem
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lego-loam" class="md-nav__link">
    LeGO-LOAM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#direct-visual-slam-using-sparse-depth-for-camera-lidar-system" class="md-nav__link">
    Direct Visual SLAM using Sparse Depth for Camera-LiDAR System
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#demo" class="md-nav__link">
    DEMO
  </a>
  
    <nav class="md-nav" aria-label="DEMO">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#frame-to-frame-motion-estimation" class="md-nav__link">
    Frame to frame motion estimation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bundle-adjustment" class="md-nav__link">
    Bundle adjustment
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scale-drift-aware-large-scale-monocular-slam" class="md-nav__link">
    Scale Drift-Aware Large Scale Monocular SLAM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tight-coupling-of-laser-scanner-and-inertial-measurements-for-a-fully-autonomous-relative-navigation-solution" class="md-nav__link">
    Tight Coupling of Laser Scanner and Inertial Measurements for a Fully Autonomous Relative Navigation Solution
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#collar-line-segments-for-fast-odometry-estimation-from-velodyne-point-clouds" class="md-nav__link">
    Collar Line Segments for Fast Odometry Estimation from Velodyne Point Clouds
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#an-explicit-loop-closing-technique-for-6d-slam" class="md-nav__link">
    An Explicit Loop Closing Technique for 6D SLAM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#real-time-loop-closure-in-2d-lidar-slam" class="md-nav__link">
    Real-Time Loop Closure in 2D LIDAR SLAM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#long-range-gps-denied-aerial-inertial-navigation-with-lidar-localization" class="md-nav__link">
    Long-range GPS-denied Aerial Inertial Navigation with LIDAR Localization
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-point-ransac-structure-from-motion-for-vehicle-mounted-cameras-by-exploiting-non-holonomic-constraints" class="md-nav__link">
    1-Point-RANSAC Structure from Motion for Vehicle-Mounted Cameras by Exploiting Non-holonomic Constraints
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visualinertial-combined-odometry-system-for-aerial-vehicles" class="md-nav__link">
    Visual–Inertial Combined Odometry System for Aerial Vehicles
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scan-segments-matching-for-pairwise-3d-alignment" class="md-nav__link">
    Scan Segments Matching for Pairwise 3D Alignment
  </a>
  
    <nav class="md-nav" aria-label="Scan Segments Matching for Pairwise 3D Alignment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evaluation-metric" class="md-nav__link">
    Evaluation Metric
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-calibration-and-visual-slam-with-a-multi-camera-system-on-a-micro-aerial-vehicle" class="md-nav__link">
    Self-Calibration and Visual SLAM with a Multi-Camera System on a Micro Aerial Vehicle
  </a>
  
    <nav class="md-nav" aria-label="Self-Calibration and Visual SLAM with a Multi-Camera System on a Micro Aerial Vehicle">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#self-calibration" class="md-nav__link">
    Self-Calibration
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visual-slam" class="md-nav__link">
    Visual SLAM
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    Implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-many-cameras-as-one" class="md-nav__link">
    Using Many Cameras as One
  </a>
  
    <nav class="md-nav" aria-label="Using Many Cameras as One">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plucker-vectors" class="md-nav__link">
    Plucker Vectors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#motion-estimation" class="md-nav__link">
    Motion Estimation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#double-window-optimisation-for-constant-time-visual-slam" class="md-nav__link">
    Double Window Optimisation for Constant Time Visual SLAM
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="2018-august-reading-reports">2018 August Reading Reports</h1>
<h2 id="an-efficient-solution-to-the-five-point-relative-pose-problem">An Efficient Solution to the Five-Point Relative Pose Problem</h2>
<p>The proposed five-point algorithm is as a hypothesis generator within a random sample consensus scheme (RANSAC).</p>
<p>The paper itself introduces a method to efficiently calculate five-point algorithm, which requires 5 corresponding points. The five-point algorithm uses <span class="arithmatex">\({q'}^TEq = 0\)</span> and the constraints of <span class="arithmatex">\(E\)</span>,
$$
\det(E) = 0
$$
and
$$
EE^TE - \frac{1}{2}\text{trace}(EE^T)E = 0
$$
to calculate the essential matrix <span class="arithmatex">\(E\)</span>. Then SVD is used to obtain the <span class="arithmatex">\(R\)</span> and <span class="arithmatex">\(t\)</span> with the cheirality constraint imposed.</p>
<hr />
<h2 id="lego-loam">LeGO-LOAM</h2>
<p><strong>Point cloud segmentation</strong> is performed to discard points that may represent unreliable features after ground separation (not use unstable features).  <strong>Two-step L-M optimization</strong> is used, which reduces the computation time. <strong>Planar features</strong> extracted from the ground are used to obtain <span class="arithmatex">\([t_z; roll; pitch]\)</span> during the first step. In the second step, the rest of the transformation <span class="arithmatex">\([t_x; t_y; yaw]\)</span> is obtained by matching <strong>edge features extracted</strong> from the segmented point cloud. The ability to perform <strong>loop closures</strong> is integrated to correct motion estimation drift.</p>
<p>Ground points or the segmented points are used for feature extraction and odometry.</p>
<hr />
<h2 id="direct-visual-slam-using-sparse-depth-for-camera-lidar-system">Direct Visual SLAM using Sparse Depth for Camera-LiDAR System</h2>
<ol>
<li>A sliding window-based tracking method.</li>
<li>Strict pose marginalization for accurate pose-graph SLAM.</li>
<li>Depth-integrated frame matching for large-scale mapping.</li>
</ol>
<p>Tracking-based visual odometry (VO) module, loop-closure module and a pose-graph optimizer.</p>
<p>Frame management uses the ratio of projectable points and certain period of time. Then marginalization is applied for old keyframes. <strong>Point selection</strong> is implemented by uniformly sampling from lidar data from 2° by 2° spatial bin.</p>
<p>In tracking, the brightness in grayscale are defined as</p>
<div class="arithmatex">\[
r(\mathbf{p}_m) = \mathcal{I}_n(\pi(\mathbf{T}^n_m \mathbf{p}_m))-\mathcal{I}_m(\pi(\mathbf{p}_m)) \\
E_{track} = \sum_{\mathbf{p} \in \Omega}\omega(r(\mathbf{p}))r(\mathbf{p})^2
\]</div>
<p><span class="arithmatex">\(\omega(\cdot)\)</span> is a weight function based on the t-distribution. And the coarse-to-fine scheme is used.</p>
<p>The selected points are projected to all keyframes with covisibility.</p>
<p>In window based optimization, the error is computed among all keyframes as</p>
<div class="arithmatex">\[
E_{win} = \sum_{\mathcal{F}_i \in \mathbf{W}_{\mathcal{F}}}\sum_{\mathbf{p}_k\in \mathbf{P}_I}\sum_{\mathbf{p}_k \in \Omega} \omega(r(\mathbf{p}_k))r(\mathbf{p}_k)^2
\]</div>
<p>ORB features and descriptor is used to do loop closure detection. Dynamic Covariance Scaling (DCS) is applied to cope with unreliable constraints.</p>
<p>The lidar points are sampled into 16 and 8 to simulate the sparse data.</p>
<p>ArUCo markers and VRS-GPS (at fixed state) are used for evaluation.</p>
<p>Future work includes illumination changes and moving objects.</p>
<hr />
<h2 id="demo">DEMO</h2>
<p>A visual odometry framework that can utilize <strong>sparse depth</strong> information from various sources to assist motion estimation. The proposed method is able to maximally utilize image information with and without depth coverage in motion estimation. Combining both features with and without depth in solving for motion.</p>
<h3 id="frame-to-frame-motion-estimation">Frame to frame motion estimation</h3>
<p>For the feature points with unknown depth, <span class="arithmatex">\(z^k_i\)</span>  and/or <span class="arithmatex">\(z^{k-1}_i\)</span> are eliminated. The <span class="arithmatex">\(m\)</span> and <span class="arithmatex">\(n\)</span> features with known and unknown depth forms a objective function w.r.t. <span class="arithmatex">\(\theta\)</span> and <span class="arithmatex">\(\mathbf{T}\)</span> with <span class="arithmatex">\(2m+n\)</span> rows. Current <span class="arithmatex">\(\bar{\mathbf{X}}^{k}_i\)</span> and the last <span class="arithmatex">\(\mathbf{X}^{k-1}_i\)</span> and <span class="arithmatex">\(\bar{\mathbf{X}}^{k-1}_i\)</span>.</p>
<p>New points in front of the camera from depth sensors are added to the <strong>depth map</strong>. It is downsized according to two angular coordinates to maintain a constant point density.</p>
<p>The depth is found by projecting onto the <strong>planar patch</strong>, which is formed by three points in the angular coordinates (2D KD-tree). For the points unavailable from the depth map but tracked for longer than a certain distance in the Euclidean space. The features are <strong>triangulated</strong> based on a Bayesian probabilistic model.</p>
<h3 id="bundle-adjustment">Bundle adjustment</h3>
<p>It takes a sequence of images and performs a <strong>batch optimization</strong> to refine the frame to frame motion estimation. One image out of every five images is the bundle adjustment input. The image sequence contains a number of eight images. It uses <strong>iSAM</strong> open source library to all selected inlier features. The information matrix contains constant first two elements and the third one is related to the depth sensor, inversely proportional to the square of the depth, or as zero if depth is known.</p>
<p>Two outputs (frame-to-frame and bundle adjustment) are integrated together.</p>
<p>In the implementation, Harris corners are tracked by the Kanade Lucas Tomasi (KLT) method. Gap between the two ends of a trajectory compared to the length of the trajectory. DEMO shares the same frame to frame motion estimation with V-LOAM. V-LOAM replaces the bundle adjustment with the scan matching.</p>
<hr />
<h2 id="scale-drift-aware-large-scale-monocular-slam">Scale Drift-Aware Large Scale Monocular SLAM</h2>
<p>The most interesting part is the backend optimization. It utilizes the 7 DoF <strong>similarity transform</strong> optimization.</p>
<p><a href="http://www.openslam.org/robotvision">Source</a></p>
<hr />
<h2 id="tight-coupling-of-laser-scanner-and-inertial-measurements-for-a-fully-autonomous-relative-navigation-solution">Tight Coupling of Laser Scanner and Inertial Measurements for a Fully Autonomous Relative Navigation Solution</h2>
<p>2D lidar is used in this work with INS. <strong>Line</strong> extracting and matching are applied to estimate the 2D pose. <strong>Tilted</strong> lidar measurements are corrected by INS. Then the <strong>lidar range</strong> values are used as measurements for the <strong>Kalman filter</strong> involving INS measurements and the states (for correct the INS error). Navigation computation includes line matching and updates.</p>
<hr />
<h2 id="collar-line-segments-for-fast-odometry-estimation-from-velodyne-point-clouds">Collar Line Segments for Fast Odometry Estimation from Velodyne Point Clouds</h2>
<p>The Collar Line Segments are designed for overcoming the sparsity and ring structure of Velodyne data.</p>
<ol>
<li>The Velodyne point cloud is transformed into a line cloud by random generation of Collar Line Segments (CLS). It is randomly generated between lines within the bins and the shortest ones are selected.</li>
<li>Registration of the line cloud representation (iteratively).  The middle points of the target lines are extracted and matched with the closest ones in the source line cloud. Corresponding points (closet points) between two lines are found to operate ICP.</li>
<li>Linear prediction is used for the transformation.</li>
<li>Mean values of the transformations among multiple scans are used for the final results.</li>
</ol>
<p><a href="https://github.com/robofit/but_velodyne_lib">Source</a></p>
<hr />
<h2 id="an-explicit-loop-closing-technique-for-6d-slam">An Explicit Loop Closing Technique for 6D SLAM</h2>
<p>An explicit loop closing heuristic (ELCH) is discussed. It <strong>dissociates</strong> the last scan of a sequence of acquired scans, <strong>reassociates</strong> it to the map, built so far by scan registration, and <strong>distributes</strong> the difference in the pose error over the SLAM graph.  Euclidean distance between the current and all previous poses and the intermediate scans are more than a threshold.</p>
<p>The transformation is distributes according to the ratio of covariance sum. Then iterative method LUM can be implemented.</p>
<hr />
<h2 id="real-time-loop-closure-in-2d-lidar-slam">Real-Time Loop Closure in 2D LIDAR SLAM</h2>
<p>A <strong>branch-and-bound approach</strong> and several <strong>precomputed grids</strong> per finished submap.</p>
<p>The submap is based on 2D occupancy map (binary Bayes Filters, p95 PR). IMU with the angular velocities can help to estimate the rotational component of the pose.</p>
<p>If  finished submaps and the correct scan are <strong>close enough</strong> based on current pose estimates, a scan matcher tries to find the scan in the submap.</p>
<p>Integral numbers of steps are adopted for loop scan matching. To solve this problem a <strong>branch and bound</strong> scan matching is introduced. It contains node selection, branching rule and computing upper bounds.</p>
<hr />
<h2 id="long-range-gps-denied-aerial-inertial-navigation-with-lidar-localization">Long-range GPS-denied Aerial Inertial Navigation with LIDAR Localization</h2>
<p>It uses a method with tightly coupled IMU with semi-intermittent global corrections using LIDAR measurements matched against an a priori Digital Elevation Model (DEM).</p>
<p>It is in the category of Terrain Referenced Navigation (TRN).</p>
<p>A region of sufficient number of line scans are accumulated. A  smooth surface-like heightmap <span class="arithmatex">\(\mathbf{I}_L\)</span> is generated, which is compared with the DEM image <span class="arithmatex">\(\mathbf{I}_D\)</span> by normalized cross-correlation value. First estimate the <span class="arithmatex">\(x\)</span> and <span class="arithmatex">\(y\)</span> axes, then a vertical correction (<span class="arithmatex">\(z\)</span>) from the elevation images (mean of the element-wise subtraction). The offset represents the as the state estimation error as measured by the lidar against the ground truth DEM.</p>
<p>Runge-Kutta integration method RK4 is used in the IMU propagation. Error state Kalman filter is used.</p>
<p>The filter is rolled back to the state at which the correction occurred and recompute the propagation.  Joseph form of the Kalman filter measurement is used, and the covariance matrix maintains symmetry by regularly  re-symmetrizing.</p>
<hr />
<h2 id="1-point-ransac-structure-from-motion-for-vehicle-mounted-cameras-by-exploiting-non-holonomic-constraints">1-Point-RANSAC Structure from Motion for Vehicle-Mounted Cameras by Exploiting Non-holonomic Constraints</h2>
<p>A restrictive motion model is introduced, allowing to parameterize the motion with only 1 point correspondence. Only one feature correspondence for computing the epipolar geometry. Once the outliers are removed, the motion can be refined using all the inliers.</p>
<p>It is theoretically valid under the assumption that the camera is positioned above the rear wheel axis of the vehicle.</p>
<p>It assume non-holonomic constraints, which result in
$$
\sin \left(\frac{\theta}{2} \right) \cdot (x'z+z'x) + \cos \left(\frac{\theta}{2} \right) \cdot (y'z-z'y) = 0
$$
Once the outliers are identified, the unconstrained motion estimate (6DoF) can be computed from all the remaining inliers using standard methods. The outlier removing approaches are based on RANSAC (reprojection error) and histogram voting (for max or median <span class="arithmatex">\(\theta^*\)</span>, within a given distance <span class="arithmatex">\(t\)</span> or using the reprojection error).</p>
<p>Degraded for non-perfectly planar motion. A hyperbolic mirror (KAIDAN 360 One VR) for real data. Harris detector is used. The speed of the car from <strong>CAN-bus</strong> is read to measure the absolute scale.</p>
<p>Switch between 1-point and 5-point. When the local circular planar motion is well verified, this reflects in a narrow histogram with a very distinguishable peak.</p>
<hr />
<h2 id="visualinertial-combined-odometry-system-for-aerial-vehicles">Visual–Inertial Combined Odometry System for Aerial Vehicles</h2>
<ol>
<li>A method that improves estimation of translation for a high-accuracy INS.</li>
<li>A feature reparametrization technique to partially remove odometry drift (equivalent to rotating the camera to a  virtual point perpendicular to the ground).</li>
</ol>
<p>Project to a virtual horizontal plane and form a function of 5 unknown parameters. Solve the equation with rotation <span class="arithmatex">\(R^V_P\)</span> as zero, then solve non-linear function iteratively. It is adapted to a robust fitting algorithm (x, y translations). For the push-broom laser, the plane is fitted into a plane, which gives the inclination of the ground.</p>
<p>Analysis of error propagation is provided. The upper bound of the position drift introduced by the yaw angle noise form the INS and altimeter/push-broom laser noise is proportional to the flying distance.</p>
<hr />
<h2 id="scan-segments-matching-for-pairwise-3d-alignment">Scan Segments Matching for Pairwise 3D Alignment</h2>
<p>Object level matching based on segmentation. Coarse alignment by matching segments across scans. Matched segments are then used to constrain point-to-point associations in regular ICP (nearest neighbor search is performed in <strong>matched</strong> segments only).</p>
<p>A pipeline combining 3D object segmentation, segment matching across scans, and alignment.</p>
<p>The scan segmentation separate the ground and objects in <em>voxel grid</em>. Center of mass is used for the segments. The procedure of <em>Segment Associations</em> is first bipartite assignment by <em>Hungarian algorithm</em> (Symmetric Shape Distance). Then <em>geometric consistency</em> is  used to check the associations and it will filter the wrong assignments. 6 DoF point-to-point ICP is applied to the associated segments, followed by point-to-plane full-scan match.</p>
<h3 id="evaluation-metric">Evaluation Metric</h3>
<p>The evaluation metric simply consists of voxelising the point cloud and returning the number of occupied voxels. The lower this number, the more crisp the point cloud and in turn the more accurate the alignment.</p>
<p>But the results are not as good as point-to-plane ICP when the displacement is small.</p>
<hr />
<h2 id="self-calibration-and-visual-slam-with-a-multi-camera-system-on-a-micro-aerial-vehicle">Self-Calibration and Visual SLAM with a Multi-Camera System on a Micro Aerial Vehicle</h2>
<p>For multiple calibrated stereo cameras and IMU. A 3-point minimal and linear solution for motion estimation. Build a graph of keyframes and constraints and use the double-window optimization method.</p>
<h3 id="self-calibration">Self-Calibration</h3>
<p>For the self-calibration, first it obtains a globally consistent map for each stereo camera via stereo vSLAM. Bundle adjustment based on dot product. Then hand-eye calibration gives an initial estimation of the inter-stereo-camera transforms. Map is merged form all stereo cameras, followed by globally consistent pose estimates. Full bundle adjustment (reprojection error of 3D scene points and chessboard corner poimts) allows to recover an accurate estimation. Another hand-eye for the final IMU-involved calibration (only rotation + hand-measurement of translation).</p>
<h3 id="visual-slam">Visual SLAM</h3>
<p>The motion estimation is based on the rotation from IMU, and form generalized epipolar constraint by substituting <span class="arithmatex">\(R\)</span> (resulting in linear form), where only minimal 3 points are needed. After RANSAC, non-linear refinement is applied to the inlier set of correspondences.</p>
<p>When no new keyframe for some time, pose estimation instead of motion estimation is used. The optimization includes the additional residuals corresponding to the error between the vertical direction associated with the MAV's estimated pose and the vertical direction measurement from the IMU.</p>
<h3 id="implementation">Implementation</h3>
<p>CenSurE feature detector is used. ORB feature descriptor is extracted. <span class="arithmatex">\(r_2Er_1\)</span> is less than a threshold, the feature match is consider as valid. Vicon is used to calculate the ground truth of the extrinsic parameters with a marked chessboard. Vicon motion capture system and loop closure error metric is used.</p>
<hr />
<h2 id="using-many-cameras-as-one">Using Many Cameras as One</h2>
<p>The generalized camera model is simplified as that it only includes the definition of the ray that the pixel samples. Plucker Vectors are used to parameterize arbitrary lines in space. <span class="arithmatex">\(q\)</span> and <span class="arithmatex">\(q'\)</span> named the  direction vector and moment vector. Fisher information matrix is used to give the optimal design of panoramic imaging systems constructed from multiple cameras.</p>
<h3 id="plucker-vectors">Plucker Vectors</h3>
<p><span class="arithmatex">\(q\)</span> is a vector of any length in the direction of the line. <span class="arithmatex">\(q' = q\times P\)</span>, for any point <span class="arithmatex">\(P\)</span> on the line. For a normalized point in the origin camera, the Plucker vector can be written as <span class="arithmatex">\(\langle \tilde{x}^T, 0 \rangle\)</span>, for other cameras, the direction vector <span class="arithmatex">\(q = R \tilde{x}\)</span> the moment vector <span class="arithmatex">\(q \times T\)</span>.</p>
<h3 id="motion-estimation">Motion Estimation</h3>
<p>The Generalized Epi-polar Constraint (GEC) can be used to estimate the motion. The pair of lines with Pluck vectors intersect iff <span class="arithmatex">\(q_b\cdot q'_a + q'_b\cdot q_a = 0\)</span>. To be coincident with Heng et al.'s work, I think the equation should be
$$
q_2<sup>TRq'_1+q_2</sup>T \lfloor T \rfloor_{\times} q_1 + {q'}_2^TRq_1=0
$$
A camera system with cameras facing in opposite directions but aligned along their optic axis is perhaps the best design for two standard cameras. The “line” ambiguity is still present. Six cameras placed to view in opposite directions along coordinate axes show no ambiguities.</p>
<hr />
<h2 id="double-window-optimisation-for-constant-time-visual-slam">Double Window Optimisation for Constant Time Visual SLAM</h2>
<p>It takes a two-level approach that combines accurate <strong>pose-point</strong> constraints in the primary region of interest with a stabilising periphery of <strong>pose-pose</strong> soft constraints. It is related to relative bundle adjustment (RBA), but RBA does not enforce metric consistency within its optimisation window. The proposed method minimise the error in both windows <strong>simultaneously</strong>.</p>
<p>An efficient approximation of covariance is defined by constant for rotation and the parallax for translation. But is not clear for the reprojection error. The method does not have a fixed keyframe, but let the damping factor of LM takes care of the gauge freedom.</p>
<p>Metric and appearance-based loop closure are introduced.</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.8492ddcf.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>